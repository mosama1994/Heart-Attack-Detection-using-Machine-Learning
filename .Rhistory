# df_2[df_2["HVY_DRINK"] == 2, "HVY_DRINK"] = 1
# df_2[df_2["DIFFALON"] == 2, "DIFFALON"] = 0
# df_2[df_2["DIFFWALK"] == 2, "DIFFWALK"] = 0
# df_2[df_2["DEPRDIS"] == 2, "DEPRDIS"] = 0
# df_2[df_2["ASTHMA"] == 2, "ASTHMA"] = 0
# df_2[df_2["STROKE"] == 2, "STROKE"] = 0
# df_2[df_2["EXERANY"] == 2, "EXERANY"] = 0
# 0: Never
# df_2[df_2["CHECKUP"] == 8, "CHECKUP"] = 0
# df_2[df_2["MEDCOST"] == 2, "MEDCOST"] = 0
# df_2[df_2["PERSDOC"] == 2, "PERSDOC"] = 0
# df_2[df_2["HLTHPLN"] == 2, "HLTHPLN"] = 0
# df_2[df_2["MENTHLTH"] == 88, "MENTHLTH"] = 0
# df_2[df_2["PHYSHLTH"] == 88, "PHYSHLTH"] = 0
# Scaling the data set from 0 to 1
# process = preProcess(df_2, method=c("range"))
# df_3 = predict(process, df_2)
write_csv(df_2, "Full Clean Data.csv")
# set.seed(699)
# train_index = createDataPartition(df_3$HEART_ATTACK, p=0.66, list = FALSE, times = 1)
# train_data = df_3[train_index,]
# test_data = df_3[-train_index,]
# train_data %>% count(HEART_ATTACK)
# test_data %>% count(HEART_ATTACK)
# df_3 %>% count(HEART_ATTACK)
# write_csv(train_data, "Training Data.csv")
# write_csv(test_data, "Testing Data.csv")
### Loading Libraries
library(glmnet)
library(ISLR)
set.seed(555) # makes the experince repeatable
### Data prep
summary(Hitters)   # Data of baseball players, including Salary which we try to predict here.
sum(is.na(Hitters$Salary))
Hitters = na.omit(Hitters)
with(Hitters, sum(is.na(Salary) ))
# expects predictor matrix and response matrix
x = model.matrix(Hitters$Salary ~.-1, data=Hitters)
y = Hitters$Salary
### Ridge regression
fit.ridge = glmnet(x, y, alpha=0)
#Note: alpha=0 is  Ridge regression
#      alpha=1 is Lasso
#      alpha <1 is Elstic net
plot(fit.ridge, xvar="lambda", label=TRUE)
cv.ridge = cv.glmnet(x, y, alpha=0) # glmnet built in cross validation
plot(cv.ridge)
#Note: alpha=0 is  Ridge regression
#      alpha=1 is Lasso
#      alpha <1 is Elstic net
plot(fit.ridge, xvar="lambda", label=TRUE)
cv.ridge = cv.glmnet(x, y, alpha=0) # glmnet built in cross validation
plot(cv.ridge)
cv.ridge$lambda
cv.ridge$lambda.min
cv.ridge$lambda.1se
plot(cv.ridge)
train = sample(1:263 , 180 , replace=FALSE)
# or
train = sample(seq(263) , 180 , replace=FALSE)
train
lasso.tr = glmnet(x[train,], y[train])
lasso.tr
pred = predict(lasso.tr , x[-train,])
dim(pred)
pred
dim(pred)
rmse = sqrt(apply((y[-train]-pred)^2, 2, mean))
plot(log(lasso.tr$lambda), rmse, type="b")
lam.best = lasso.tr$lambda[order(rmse)[1]]
lam.best
coef(lasso.tr, s=lam.best)
##############################
### Example Subset selection
#Subset selection
library(ISLR)
summary(Hitters)   # Data of baseball players, including Salary which we try to predict here.
Hitters = na.omit(Hitters)
with(Hitters, sum(is.na(Salary)))
#Best Subset Regression.
#Using "leaps" library.
library(leaps)
regfit_full = regsubsets(Salary ~ . , data = Hitters)
summary(regfit_full)
regfit_full = regsubsets(Salary ~ . , data = Hitters)
summary(regfit_full)
library(ISLR)
library(MASS)
View(Boston)
library(glmnet)
x = model.matrix(Boston$medv ~.-1, data=Boston)
y = Boston$medv
### Ridge regression
fit.ridge = glmnet(x, y, alpha=0)
#Note: alpha=0 is  Ridge regression
#      alpha=1 is Lasso
#      alpha <1 is Elstic net
plot(fit.ridge, xvar="lambda", label=TRUE)
cv.ridge = cv.glmnet(x, y, alpha=0) # glmnet built in cross validation
plot(cv.ridge)
cv.ridge$lambda.1se
### Lasso regression
fit.lasso = glmnet(x,y)
plot(fit.lasso, xvar="lambda", label=TRUE)
cv.lasso = cv.glmnet(x, y) # glmnet built in cross validation
plot(cv.lasso)
coef(cv.lasso)
### cross validation
dim(Hitters)
### cross validation
dim(Boston)
train = sample(1:263 , 180 , replace=FALSE)
cv.ridge$lambda.1se
coef(cv.ridge)
### cross validation
dim(Boston)
### cross validation
dim(Hitters)
train = sample(1:506 , 334 , replace=FALSE)
# or
train = sample(seq(506) , 334 , replace=FALSE)
train
lasso.tr = glmnet(x[train,], y[train])
lasso.tr
pred = predict(lasso.tr , x[-train,])
dim(pred)
rmse = sqrt(apply((y[-train]-pred)^2, 2, mean))
plot(log(lasso.tr$lambda), rmse, type="b")
lam.best = lasso.tr$lambda[order(rmse)[1]]
lam.best
coef(lasso.tr, s=lam.best)
coef
ridge.tr = glmnet(x[train,], y[train], alpha = 0)
pred_ridge = predict(ridge.tr, x[-train,])
rmse_ridge = sqrt(apply((y[-train]-pred_ridge)^2, 2, mean))
plot(log(ridge.tr$lambda), rmse, type="b")
lam.best.ridge = ridge.tr$lambda[order(rmse_ridge)[1]]
lam.best.ridge
coef(ridge.tr, s=lam.best.ridge)
plot(log(ridge.tr$lambda), rmse_ridge, type="b")
lam.best.ridge = ridge.tr$lambda[order(rmse_ridge)[1]]
lam.best.ridge
coef(ridge.tr, s=lam.best.ridge)
coef(lasso.tr, s=lam.best)
plot(log(lasso.tr$lambda), rmse, type="b")
coef(ridge.tr, s=lam.best.ridge)
lam.best
lam.best.ridge
cv.lasso = cv.glmnet(x, y) # glmnet built in cross validation
plot(cv.lasso)
coef(cv.lasso)
coef(cv.ridge)
cv.ridge$lambda.1se
plot(cv.ridge)
library(tidyverse)
library(caret)
library(sampling)
df = read_csv("Heart Attack Detection Dataset.csv", col_names = TRUE)
spec(df)
# Renaming columns in the dataset
df_1 = rename(df, HLTHPLN = HLTHPLN1, PERSDOC = PERSDOC2, CHECKUP = CHECKUP1, EXERANY = EXERANY2,
SLEPTIM = SLEPTIM1, STROKE = CVDSTRK3, ASTHMA = ASTHMA3, DEPRDIS = ADDEPEV3,
EDUCATION = EDUCAG, EMPLOYMENT_STATUS = EMPLOY1, INCOME_CAT = INCOMG, GENDER = SEX,
AGE_CAT = AGEG5YR, BMI_CAT = BMI5CAT, SMOKER_CAT = SMOKER3, HVY_DRINK = RFDRHV7,
HEART_ATTACK = CVDINFR4)
# Checking dimensions of the dataset
dim(df_1)
# Checking null values in columns
sapply(df_1, function(x) sum(is.na(x)))
# Too many null values in pregnant column so we will remove that column.
df_1 = select(df_1, -c(PREGNANT, POORHLTH))
# Filtering values from dataset. Removing rows with missing data.
df_1[is.na(df_1$GENHLTH), "GENHLTH"] = median(df_1$GENHLTH, na.rm = TRUE)
df_1[is.na(df_1$PHYSHLTH), "PHYSHLTH"] = median(df_1$PHYSHLTH, na.rm = TRUE)
df_1[is.na(df_1$MENTHLTH), "MENTHLTH"] = median(df_1$MENTHLTH, na.rm = TRUE)
df_1[is.na(df_1$HLTHPLN), "HLTHPLN"] = median(df_1$HLTHPLN, na.rm = TRUE)
df_1[is.na(df_1$PERSDOC), "PERSDOC"] = median(df_1$PERSDOC, na.rm = TRUE)
df_1[is.na(df_1$MEDCOST), "MEDCOST"] = median(df_1$MEDCOST, na.rm = TRUE)
df_1[is.na(df_1$CHECKUP), "CHECKUP"] = median(df_1$CHECKUP, na.rm = TRUE)
df_1[is.na(df_1$EXERANY), "EXERANY"] = median(df_1$EXERANY, na.rm = TRUE)
df_1[is.na(df_1$SLEPTIM), "SLEPTIM"] = median(df_1$SLEPTIM, na.rm = TRUE)
df_1[is.na(df_1$STROKE), "STROKE"] = median(df_1$STROKE, na.rm = TRUE)
df_1[is.na(df_1$ASTHMA), "ASTHMA"] = median(df_1$ASTHMA, na.rm = TRUE)
df_1[is.na(df_1$DEPRDIS), "DEPRDIS"] = median(df_1$DEPRDIS, na.rm = TRUE)
df_1[is.na(df_1$EDUCATION), "EDUCATION"] = median(df_1$EDUCATION, na.rm = TRUE)
df_1[is.na(df_1$EMPLOYMENT_STATUS), "EMPLOYMENT_STATUS"] = median(df_1$EMPLOYMENT_STATUS, na.rm = TRUE)
df_1[is.na(df_1$INCOME_CAT), "INCOME_CAT"] = median(df_1$INCOME_CAT, na.rm = TRUE)
df_1[is.na(df_1$DIFFWALK), "DIFFWALK"] = median(df_1$DIFFWALK, na.rm = TRUE)
df_1[is.na(df_1$DIFFALON), "DIFFALON"] = median(df_1$DIFFALON, na.rm = TRUE)
df_1[is.na(df_1$GENDER), "GENDER"] = median(df_1$GENDER, na.rm = TRUE)
df_1[is.na(df_1$AGE_CAT), "AGE_CAT"] = median(df_1$AGE_CAT, na.rm = TRUE)
df_1[is.na(df_1$BMI_CAT), "BMI_CAT"] = median(df_1$BMI_CAT, na.rm = TRUE)
df_1[is.na(df_1$SMOKER_CAT), "SMOKER_CAT"] = median(df_1$SMOKER_CAT, na.rm = TRUE)
df_1[is.na(df_1$HVY_DRINK), "HVY_DRINK"] = median(df_1$HVY_DRINK, na.rm = TRUE)
df_1 %>% count(HEART_ATTACK)
summary(df_1)
# df_2 = df_1 %>%
#   filter(HEART_ATTACK %in% c(1,2) & HVY_DRINK %in% c(1,2) & SMOKER_CAT !=9 & BMI_CAT %in% c(1,2,3,4) &
#           AGE_CAT != 14 & DIFFALON %in% c(1,2) & DIFFWALK %in% c(1,2) & INCOME_CAT != 9 &
#           EMPLOYMENT_STATUS %in% c(1,2,3,4,5,6,7,8) & DEPRDIS %in% c(1,2) & EDUCATION != 9
#         & ASTHMA %in% c(1,2) & STROKE %in% c(1,2) & SLEPTIM %in% seq(1,24) & EXERANY
#         %in% c(1,2) & CHECKUP %in% c(1,2,3,4,8) & MEDCOST %in% c(1,2) & PERSDOC %in%
#           c(1,2) & HLTHPLN %in% c(1,2) & MENTHLTH %in% c(seq(1,30),88) &
#           PHYSHLTH %in% c(seq(1,30),88) & GENHLTH %in% c(1,2,3,4,5))
df_2 = df_1 %>%
filter(HEART_ATTACK %in% c(1,2))
# Checking Null Values in all columns
sapply(df_2, function(x) sum(is.na(x)))
# Checking dimensions of dataset again
dim(df_2)
# Checking distribution of class variable
df_2 %>% count(HEART_ATTACK)
library(MASS)
library(ISLR)
library(ISLR)
library(MASS)
a = lm(Boston$medv ~ ., data = Boston)
a
library(glmnet)
x = model.matrix(Boston$medv ~.-1, data=Boston)
model.matrix(Boston$medv ~.-1, data=Boston)
a = lm(Boston$medv ~ .-1, data = Boston)
lm(Boston$medv ~ .-1, data = Boston)
model.matrix(Boston$medv ~.-1, data=Boston)
fit.lasso = glmnet(x, y, alpha=1)
x = model.matrix(Boston$medv ~.-1, data=Boston)
y = Boston$medv
fit.lasso = glmnet(x, y, alpha=1)
glmnet(x, y, alpha=1)
plot(fit.lasso, xvar="lambda", label=TRUE)
plot(fit.lasso, label=TRUE)
plot(fit.lasso, xvar="lambda", label=TRUE)
install.packages("rtweet")
library(rtweet)
api_key <- "j3lR217MlveVJcjYKcOwGIeT3"
api_secret_key <- "yWrss2tl2NSSrjQK0PD0sjBGTiza9ozxXNjEIiY7gw4GBxAziH"
access_token <- "1484439484313731075-3BdUnaMv8JfNOqKHNpZBPSbWc6R2X2"
access_token_secret <- "OzdGnrfk19P3NMRWIQF3YGWpCorSX6TDzO9lpHDLI042K"
token <- create_token(
app = "rstatsjournalismresearch",
consumer_key = api_key,
consumer_secret = api_secret_key,
access_token = access_token,
access_secret = access_token_secret)
View(token)
View(token)
covid_tweets <- rtweet::get_timeline(c("Covid-19"), n = 20, parse=T, token=token)
covid_tweets <- rtweet::get_timeline(c("Covid-19"), n = 20, parse=T, token=token)
require(dplyr)
require(xml2)
require(rvest)
html_dat
dat %
html_nodes(‘.VDXfz’) %>%
html_attr(‘href’)) %>%
mutate(Link = gsub(“./articles/”,”https://news.google.com/articles/”,Link))
article_all <- google %>% html_nodes("article")
google = read_html("https://news.google.com/search?q=Covid-19&hl=en-US&gl=US&ceid=US%3Aen")
article_all <- google %>% html_nodes("article")
news = article_all %>% html_text()
news
google = read_html("https://news.google.com/search?q=Covid-19&hl=en-US&gl=US&ceid=US%3Aen")
article_all <- google %>% html_nodes("DY5T1d RZIKme")
news = article_all %>% html_text()
news
article_all <- google %>% html_nodes(google, ".DY5T1d.RZIKme")
news = article_all %>% html_text()
news
article_all <- google %>% html_nodes(".DY5T1d.RZIKme")
news = article_all %>% html_text()
news
article_all <- google %>% html_nodes(".DY5T1d")
news = article_all %>% html_text()
news
article_all <- google %>% html_nodes("a.DY5T1d")
news = article_all %>% html_text()
news
news
install.packages("syuzhet")
library(syuzhet)
get_nrc_sentiment(news[1])
get_nrc_sentiment(news)
news[10:30]
news[11:30]
get_nrc_sentiment(news[11:30])
install.packages("word2vec")
# Sentiment scores using
word2vec(news[11])
library(word2vec)
# Sentiment scores using
word2vec(news[11])
news[11]
write.csv(news(11:30), "Google News.csv")
write.csv(news[11:30], "Google News.csv")
write.csv(news[11:30], "Google News.csv", row.names = FALSE, col.names = c("Headline"))
write.csv(news[11:30], "Google News.csv", row.names = FALSE)
write.csv(news[11:30], "Google News.csv", row.names = FALSE, col.names = c("Osama"))
write.csv(news[11:30], "Google News.csv", col.names = c("Osama"))
write.csv(news[11:30], "Google News.csv", row.names = FALSE, col.names = c("i", "Osama"))
write.csv(news[11:30], "Google News.csv", row.names = FALSE)
write.csv(news[11:30], "Google News.csv", col.names = FALSE)
write.csv(news[11:30], "Google News.csv", col.names = c("News"))
library(rvest)
write.csv(news[11:30], "Google News.csv", row.names = FALSE)
library(ISLR)
library(MASS)
library(glmnet)
a = lm(Boston$medv ~ .-1, data = Boston)
lm(Boston$medv ~ .-1, data = Boston)
x = model.matrix(Boston$medv ~.-1, data=Boston)
y = Boston$medv
fit.lasso = glmnet(x, y, alpha=1)
plot(fit.lasso, xvar="lambda", label=TRUE)
cv.lasso = cv.glmnet(x, y, alpha=1)
plot(cv.lasso)
best_lambda_lasso = cv.lasso$lambda.min
coef(cv.lasso)
cv.lasso$lambda.min
cv.ridge = cv.glmnet(x, y, alpha = 0)
plot(cv.ridge)
best_lambda_ridge = cv.ridge$lambda.min
coef(cv.ridge)
cv.ridge$lambda.min
x = model.matrix(Boston$medv ~.-1, data=Boston)
library(ISLR)
library(MASS)
library(glmnet)
a = lm(Boston$medv ~ .-1, data = Boston)
x = model.matrix(Boston$medv ~.-1, data=Boston)
y = Boston$medv
fit.lasso = glmnet(x, y, alpha=1)
plot(fit.lasso, xvar="lambda", label=TRUE)
cv.lasso = cv.glmnet(x, y, alpha=1)
plot(cv.lasso)
best_lambda_lasso = cv.lasso$lambda.min
coef(cv.lasso)
cv.lasso$lambda.min
coef(cv.lasso)
index(cv.lasso)
cv.lasso$cvm
cv.lasso$index
plot(log(lasso.tr$lambda), rmse, type="b")
### cross validation
dim(Hitters)
train = sample(1:263 , 180 , replace=FALSE)
# or
train = sample(seq(263) , 180 , replace=FALSE)
train
lasso.tr = glmnet(x[train,], y[train])
lasso.tr
pred = predict(lasso.tr , x[-train,])
dim(pred)
rmse = sqrt(apply((y[-train]-pred)^2, 2, mean))
plot(log(lasso.tr$lambda), rmse, type="b")
lam.best = lasso.tr$lambda[order(rmse)[1]]
lam.best
coef(lasso.tr, s=lam.best)
### Lasso regression
fit.lasso = glmnet(x,y)
plot(fit.lasso, xvar="lambda", label=TRUE)
cv.lasso = cv.glmnet(x, y) # glmnet built in cross validation
plot(cv.lasso)
coef(cv.lasso)
cv.lasso$lambda
cv.lasso$index
cv.lasso$lambda.1se
cv.lasso$lambda.min
plot(cv.lasso)
fit.lasso = glmnet(x, y, alpha=1)
plot(fit.lasso, xvar="lambda", label=TRUE)
cv.lasso = cv.glmnet(x, y, alpha=1)
plot(cv.lasso)
cv.lasso = cv.glmnet(x, y, alpha=1)
plot(cv.lasso)
cv.lasso = cv.glmnet(x, y, alpha=1)
plot(cv.lasso)
cv.lasso = cv.glmnet(x, y, alpha=1)
plot(cv.lasso)
cv.lasso$index
cv.lasso$lambda.1se
cv.lasso$lambda.min
coef(cv.lasso, s=cv.lasso$lambda.min)
coef(cv.lasso, s=cv.lasso$lambda.1se)
cv.ridge = cv.glmnet(x, y, alpha = 0)
plot(cv.ridge)
cv.ridge$lambda.min
coef(cv.ridge, s = cv.ridge$lambda.min)
coef(cv.lasso)
lam.best = lasso.tr$lambda[order(rmse)[1]]
lam.best
plot(log(lasso.tr$lambda), rmse, type="b")
cv.lasso$index
lam.best
coef(lasso.tr, s=lam.best)
log(10)
cv.lasso$lambda.1se
cv.lasso$index
cv.lasso$lambda.min
x = model.matrix(Boston$medv ~.-1, data=Boston)
y = Boston$medv
fit.lasso = glmnet(x, y, alpha=1)
plot(fit.lasso, xvar="lambda", label=TRUE)
cv.lasso = cv.glmnet(x, y, alpha=1)
plot(cv.lasso)
cv.lasso$lambda.min
coef(cv.lasso, s=cv.lasso$lambda.min)
cv.ridge = cv.glmnet(x, y, alpha = 0)
plot(cv.ridge)
best_lambda_ridge = cv.ridge$lambda.min
cv.ridge$lambda.min
coef(cv.ridge, s = cv.ridge$lambda.min)
lasso.tr
pred = predict(lasso.tr , x[-train,])
dim(pred)
rmse = sqrt(apply((y[-train]-pred)^2, 2, mean))
plot(log(lasso.tr$lambda), rmse, type="b")
pred
x[-train,]
lasso.tr
pred = predict(lasso.tr , x[-train,])
dim(pred)
rmse = sqrt(apply((y[-train]-pred)^2, 2, mean))
plot(log(lasso.tr$lambda), rmse, type="b")
lam.best = lasso.tr$lambda[order(rmse)[1]]
lam.best
coef(lasso.tr, s=lam.best)
coef(cv.lasso)
coef(cv.lasso, s=cv.lasso$lambda.min)
install.packages("cluster")
library('cluster')
data(votes.repub)
dv <- diana(votes.repub, metric = "manhattan", stand = TRUE)
print(dv)
plot(dv)
data(votes.repub)
votes.repub
setwd("C:/Users/muham/Downloads/Semester 2/CS 699/Semester Project")
library(tidyverse)
df = read_csv("Heart Attack Detection Dataset.csv", col_names = TRUE)
spec(df)
df_1 = rename(df, HLTHPLN = HLTHPLN1, PERSDOC = PERSDOC2, CHECKUP = CHECKUP1, EXERANY = EXERANY2,
SLEPTIM = SLEPTIM1, STROKE = CVDSTRK3, ASTHMA = ASTHMA3, DEPRDIS = ADDEPEV3,
EDUCATION = EDUCAG, EMPLOYMENT_STATUS = EMPLOY1, INCOME_CAT = INCOMG, GENDER = SEX,
AGE_CAT = AGEG5YR, BMI_CAT = BMI5CAT, SMOKER_CAT = SMOKER3, HVY_DRINK = RFDRHV7,
HEART_ATTACK = CVDINFR4)
dim(df_1)
sapply(df_1, function(x) sum(is.na(x)))
spec(df, show_col_types = FALSE)
sapply(df_1, function(x) sum(is.na(x)))
a = sapply(df_1, function(x) sum(is.na(x)))
df_1[is.na(df_1$GENHLTH), "GENHLTH"]
df_1[is.na(df_1$GENHLTH) & df_1$HEART_ATTACK == 1, "GENHLTH"]
df_1[is.na(df_1$GENHLTH) & df_1$HEART_ATTACK == 2, "GENHLTH"]
df_1 %>% count(HEART_ATTACK)
df_1[is.na(df_1$GENHLTH) & df_1$HEART_ATTACK == 1, "GENHLTH"]
df_1[is.na(df_1$GENHLTH) & df_1$HEART_ATTACK == 2, "GENHLTH"]
df_1[is.na(df_1$GENHLTH) & df_1$HEART_ATTACK == 2, c("GENHLTH", "HEART_ATTACK")]
df_1[is.na(df_1$GENHLTH) & df_1$HEART_ATTACK = 2, c("GENHLTH", "HEART_ATTACK")]
df_1[is.na(df_1$GENHLTH) & df_1$HEART_ATTACK == 2, c("GENHLTH", "HEART_ATTACK")]
df_1[is.na(df_1$GENHLTH), c("GENHLTH", "HEART_ATTACK")]
df_1 %>% count(HEART_ATTACK)
df_1[is.na(df_1$GENHLTH) & df_1$HEART_ATTACK %in% c(1), "GENHLTH"]
df_1[is.na(df_1$GENHLTH) & df_1$HEART_ATTACK %in% c(2), c("GENHLTH", "HEART_ATTACK")]
df_1$GENHLTH
df_1[HEART_ATTACK %in% c(1), "GENHLTH"]
df_1[df_1$HEART_ATTACK %in% c(1), "GENHLTH"]
df_1$HEART_ATTACK %in% c(2)
df_1[df_1$HEART_ATTACK %in% c(2)
df_1[df_1$HEART_ATTACK %in% c(2), "GENHLTH"]
colnames(df_1)
for (name in colnames(df_1)) {
df_1[is.na(df_1$name) & df_1$HEART_ATTACK %in% c(1), name] = median(df_1[df_1$HEART_ATTACK %in% c(1), name], na.rm = TRUE)
df_1[is.na(df_1$name) & df_1$HEART_ATTACK %in% c(2), name] = median(df_1[df_1$HEART_ATTACK %in% c(2), name], na.rm = TRUE)
}
median(df_1[df_1$HEART_ATTACK %in% c(1), "GENHLTH"], na.rm = TRUE)
nrow(df_1[df_1$HEART_ATTACK %in% c(1), "GENHLTH"])
median(df_1[df_1$HEART_ATTACK %in% c(1), "GENHLTH"], na.rm = TRUE)
df_1[df_1$HEART_ATTACK %in% c(1), "GENHLTH"]
median(df_1[df_1$HEART_ATTACK %in% c(1), "GENHLTH"], na.rm = TRUE)
median(df_1[, "GENHLTH"])
median(df_1$MENTHLTH, na.rm = TRUE)
median(df_1[, 3])
library(tidyverse)
df = read_csv("Heart Attack Detection Dataset.csv", col_names = TRUE)
spec(df)
df_1 = rename(df, HLTHPLN = HLTHPLN1, PERSDOC = PERSDOC2, CHECKUP = CHECKUP1, EXERANY = EXERANY2,
SLEPTIM = SLEPTIM1, STROKE = CVDSTRK3, ASTHMA = ASTHMA3, DEPRDIS = ADDEPEV3,
EDUCATION = EDUCAG, EMPLOYMENT_STATUS = EMPLOY1, INCOME_CAT = INCOMG, GENDER = SEX,
AGE_CAT = AGEG5YR, BMI_CAT = BMI5CAT, SMOKER_CAT = SMOKER3, HVY_DRINK = RFDRHV7,
HEART_ATTACK = CVDINFR4)
dim(df_1)
a = sapply(df_1, function(x) sum(is.na(x)))
df_1 = select(df_1, -c(PREGNANT, POORHLTH))
median(df_1[, 3])
df_1[, 3]
median(as.vector(df_1[, 3]))
as.vector(df_1[, 3])
as.numeric(df_1[, 3])
as.numeric(as.vector(df_1[, 3]))
library(tidyverse)
df = read_csv("Heart Attack Detection Dataset.csv", col_names = TRUE)
spec(df)
df_1 = rename(df, HLTHPLN = HLTHPLN1, PERSDOC = PERSDOC2, CHECKUP = CHECKUP1, EXERANY = EXERANY2,
SLEPTIM = SLEPTIM1, STROKE = CVDSTRK3, ASTHMA = ASTHMA3, DEPRDIS = ADDEPEV3,
EDUCATION = EDUCAG, EMPLOYMENT_STATUS = EMPLOY1, INCOME_CAT = INCOMG, GENDER = SEX,
AGE_CAT = AGEG5YR, BMI_CAT = BMI5CAT, SMOKER_CAT = SMOKER3, HVY_DRINK = RFDRHV7,
HEART_ATTACK = CVDINFR4)
dim(df_1)
a = sapply(df_1, function(x) sum(is.na(x)))
df_1 = select(df_1, -c(PREGNANT, POORHLTH))
median(as.numeric(as.vector(df_1[, 3])))
median(df_1[, 3])
